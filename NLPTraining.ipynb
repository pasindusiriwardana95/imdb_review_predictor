{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae0d85c-f188-4009-ba2a-960a38750f92",
   "metadata": {},
   "source": [
    "# Bag of words example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad50b879-7853-4808-bc61-2b3db463aca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words\n",
      "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
      "Vocabulary\n",
      "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "word_encoding = 1\n",
    "\n",
    "def bag_of_words(text):\n",
    "    global word_encoding\n",
    "    \n",
    "    words = text.lower().split(\" \")\n",
    "    bag = {}\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            encoding = vocab[word] # get the encoding value for the word from vocab\n",
    "        else:\n",
    "            vocab[word] = word_encoding\n",
    "            encoding = word_encoding\n",
    "            word_encoding += 1\n",
    "            \n",
    "        if encoding in bag:\n",
    "            bag[encoding] += 1\n",
    "        else:\n",
    "            bag[encoding] = 1\n",
    "    return bag\n",
    "\n",
    "text = \"this is a test to see if this test will work is is test a a\"\n",
    "bag = bag_of_words(text)\n",
    "print(\"Bag of words\")\n",
    "print(bag)\n",
    "print(\"Vocabulary\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44f80c-d321-4714-9d86-cac16cd7d8c9",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "    * eg:- whether a movie review is positive or negative or neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ee7d34-67f4-4a3a-8d37-3398e3405c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564832cd-2218-48db-a8a5-c731308e3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 88584 # number of unique words there can be\n",
    "maxlen = 250\n",
    "batch_size = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0179b482-9bc7-4482-b081-b78f93c807a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0cf9bc-91a8-46c2-82d9-cef678dd119c",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "    * length of the records are not the same, inorder to feed the data to the model the record lengths must be the same - make length into the maxlen for all the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc83c81-a0e9-4bfe-9378-666f84816fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data, maxlen)\n",
    "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data, maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf54dd5-0172-4066-9adc-a776177b7afb",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0ce40f-f79e-4914-b52f-40c66e9146c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(vocab_size, 32),       # eventhough we have already converted the values into integers, by using this embedding layer we can  convert those ints into meaningful vectors\n",
    "            tf.keras.layers.LSTM(32),                        # 32 is the number of dimensions for every single word.. will impleemnt the memory capsity\n",
    "            tf.keras.layers.Dense(1, activation = \"sigmoid\") # sigmoid was given as the activation function because it is easier to predict because the predicted values will anyway be between 0 and 1\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb54efc6-9c72-4cf0-b1e5-7709e101b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47657c6d-1cb2-4ba4-b11b-b7348786b0a9",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0fb401f-b2dd-4985-9b8a-0fe5540c7aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 54s 79ms/step - loss: 0.4540 - acc: 0.7757 - val_loss: 0.3202 - val_acc: 0.8648\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.2620 - acc: 0.8976 - val_loss: 0.3264 - val_acc: 0.8562\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 66s 105ms/step - loss: 0.2060 - acc: 0.9241 - val_loss: 0.3126 - val_acc: 0.8676\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.1685 - acc: 0.9406 - val_loss: 0.2903 - val_acc: 0.8802\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1375 - acc: 0.9530 - val_loss: 0.4191 - val_acc: 0.8730\n"
     ]
    }
   ],
   "source": [
    "# 1. compile\n",
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "\n",
    "# 2. Train\n",
    "history = model.fit(\n",
    "            x = train_data,\n",
    "            y = train_labels,\n",
    "            epochs = 5,\n",
    "            validation_split = 0.2 # 20% of the data wont be fed to be trained but will be used to validate the trained model\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0a65c-0b49-4780-aab8-9508e42438c8",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "078d719b-81a3-45f8-be48-b23e6894b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 21s 26ms/step - loss: 0.5035 - acc: 0.8466\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb0e9ed-b97d-418c-9bfe-dcc036517ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5035121440887451, 0.846560001373291]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0566e4-fc52-47db-92ce-b364abcb2a5a",
   "metadata": {},
   "source": [
    "# Making predictions\n",
    "    * When making predictions we need make sure that the input is converted to integer then a vector inorder for the trained model can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eefc0f0-6c4e-41b5-bd82-e5c23ed5a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index() # the vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75db23c1-d532-426d-b36d-3c66d19ec00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    tokens = keras.preprocessing.text.text_to_word_sequence(text)                # convert text into a sequence of words\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]  # map the word into integers\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(\n",
    "               sequences = [tokens],\n",
    "               maxlen = maxlen\n",
    "           )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3122d3a6-c445-4e10-9cd5-8cbc2caca481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "# keras.preprocessing.text.text_to_word_sequence\n",
    "\n",
    "sample_text = 'This is a sample sentence.'\n",
    "x = keras.preprocessing.text.text_to_word_sequence(\n",
    "        input_text = sample_text,\n",
    "        lower = False,\n",
    "        split = ' '\n",
    "    )\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9993102d-e056-46e4-b98f-51d4f6084a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
     ]
    }
   ],
   "source": [
    "text = \"That movie was just amazing, so amazing\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a84e5d0e-a7d6-44d6-a01b-1df404bc38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = {value: key for (key,value) in word_index.items()} # reversing the word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c9716fa-27d0-4fe8-9ed8-fafa038e8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_integers(integers):\n",
    "    pad = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != pad:\n",
    "            text = text + reverse_word_index[num] + \" \"\n",
    "    return text[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "808730fc-dbf8-436b-a7bd-bce188e607c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was just amazing so amazing\n"
     ]
    }
   ],
   "source": [
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e22f9402-cd11-4d9a-9b17-01be821cec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "\n",
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1, 250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred)\n",
    "    print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "815b5722-0659-47bb-9507-02880d14f08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "[0.8425161]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "[0.9073368]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[0.07161315]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "text = \"That movie was just amazing, so amazing\"\n",
    "predicted_value = predict(text)\n",
    "\n",
    "# if math.floor(predicted_value) >= 0.5:\n",
    "#     print(\"Positive review\")\n",
    "# else:\n",
    "#     print(\"Negative review\")\n",
    "\n",
    "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
    "predict(negative_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22c12e-23b0-48e0-9b0f-da2bf0b454d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
